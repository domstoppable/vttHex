---
title: "Vibey Transcribey Results"
output: html_document
---

R code for processing vibey-transcribey data

Working directory should be `/software/analysis`

```{r load-helpers, include = FALSE}
    # helper functions and folder setup

    theme_colors <- c("#E3E3E3","#E69F00", "#56B4E9", "#009E73", "#F0E442")
    #theme_colors <- c("#111111","#E69F00", "#56B4E9", "#009E73", "#F0E442")

    # ensure output plots exist
    if (!file.exists("../analysis-output/plots")) {
        dir.create("../analysis-output/plots", recursive = TRUE)
    }

    # Load helper funcs and dataframes and set directory
    phone_translate <- read.csv("../aux-data/phoneme-translate.csv")
    phone_translate$phone_type <- as.factor(phone_translate$phone_type)
    training_lexicon <- read.csv("../aux-data/training-lexicon.csv")

    load_eval_files <- function(file_pattern, create_correct_column = TRUE) {
        # find matching files, combine into single df
        setwd("../data/evals")
        df_files <- list.files(".", file_pattern)
        df <- dplyr::bind_rows(lapply(df_files, read.csv))
        setwd("../../analysis")

        # Remove unneeded columns and rows
        df <- subset(df, select = -c(timestamp, facilitator, event, item))
        df <- dplyr::filter(df, stimulus != "")

        if (create_correct_column) {
            df$correct <- as.integer(df$stimulus == df$selection)
        }

        # configure data types
        ordered_conditions <- c("Pre-test", "Post-test")
        df <- within(df, {
            pid <- as.factor(pid)
            condition <- factor(
                condition,
                levels = ordered_conditions,
                labels = ordered_conditions
            )
            selection <- as.factor(selection)
            stimulus <- as.factor(stimulus)
        })

        return(df)
    }

    merge_eval_files_with_training <- function(eval_df, train_df) {
        df <- merge(eval_df, train_df, key = "pid", all.x = TRUE)

        df$group <- ifelse(is.na(df$training_word_exposures), "Control", "Experimental")
        df$group <- as.factor(df$group)

        df$training_word_exposures <- replace(
            df$training_word_exposures,
            is.na(df$training_word_exposures),
            0
        )

        # normalize training_word_exposures
        df$training_word_exposures_n <- df$training_word_exposures / max(df$training_word_exposures, na.rm = TRUE)

        return(df)
    }

    bin_lme <- function(formula, data) {
        data <- rlang::enexpr(data)
        model_call <- rlang::expr(lme4::glmer(
            formula = formula,
            data = !!data,
            family = binomial,
            control = lme4::glmerControl(optimizer = "bobyqa")
        ))

        model <- eval(model_call)
        print(summary(model))

        return(model)
    }

    save_plot <- function(plot = NULL, path = NULL, filename = NULL, width = 6, height = 6, extension = "svg", theme_overrides = ggplot2::theme()) {
        if (is.null(plot)) {
            plot <- ggplot2::last_plot()
        }

        if (is.null(path)) {
            path <- "analysis-output/plots"
        }

        if (is.null(filename)) {
            filename <- stringr::str_replace_all(tolower(plot$labels$title), " ", "_")
        }

        filename <- sprintf("%s/%s.%s", path, filename, extension)

        if (extension == "svg") {
            width <- width * 2/3
            height <- height * 2/3
        }

        plot <- plot +
            ggplot2::scale_color_manual(values = theme_colors) +
            ggplot2::scale_fill_manual(values = theme_colors) +
            ggplot2::theme(
                plot.title = ggplot2::element_blank(),
                plot.background = ggplot2::element_rect(fill = "black"),
                panel.grid = ggplot2::element_blank(),
                panel.background = ggplot2::element_rect(fill="#0A0A0A"),
                panel.grid.major = ggplot2::element_line(color = "#333333", size = 0.5),
                panel.grid.minor = ggplot2::element_line(color = "#222222", size = 0.25),
                legend.background = ggplot2::element_rect(fill = "black", color = "#888888"),
                legend.key = ggplot2::element_blank(),
                text = ggplot2::element_text(color = "white", family = "arial"),
                axis.text.y = ggplot2::element_text(colour = "#BBBBBB", family = "arial"),
                axis.text.x = ggplot2::element_text(colour = "#BBBBBB", family = "arial"),
                axis.line.x.bottom = ggplot2::element_line(color = "#999999"),
                axis.line.y.left = ggplot2::element_line(color = "#999999"),
        ) + theme_overrides

        ggplot2::ggsave(
            plot = plot,
            file = filename,
            width = width, height = height,
            dpi = 300
        )
    }

    get_logistic_odds_results <- function(model, effect_index = NULL) {
        # https://www.statology.org/how-to-report-logistic-regression-results/

        coeffs <- summary(model)$coefficients

        effect_index <- ifelse(is.null(effect_index), nrow(coeffs))

        coeff <- coeffs[effect_index, 1]
        err <- coeffs[effect_index, 1]

        return(c(
            (exp(coeff)-1)*100,
            exp(coeff + (1.96*err)),
            exp(coeff - (1.96*err))
        ))
    }
```

# TRAINING DATA (by phoneme)
```{r load-training-data-phones, echo = FALSE}
    # Load training files from data/training/*.csv

    setwd("../data/training")

    training_files <- list.files(".", "*.csv")
    training_data <- data.frame()

    for (idx in seq_along(training_files)) {
        tmp_df <- read.csv(training_files[idx])
        if (nrow(tmp_df) > 0) {
            training_data <- dplyr::bind_rows(training_data, tmp_df)
        }
    }

    setwd("../../analysis")

    # calculate how much time has elapsed between rows
    # from this we can determine training day index
    training_data <- training_data[
        order(training_data$PID, training_data$Timestamp),
    ]

    training_data$datetime <- as.POSIXct(sub("T", " ", training_data$Timestamp))
    # $timedelta will be in seconds
    is_repeated_pid <- training_data$PID == dplyr::lag(training_data$PID)
    training_data$timedelta <- ifelse(
        is_repeated_pid & !is.na(dplyr::lag(training_data$datetime)),
        training_data$datetime - dplyr::lag(training_data$datetime),
        Inf
    )

    # Compute training session idx's
    # we consider a gap of 1 hour or more to count as a new training session
    training_data$training_session_inc <- ifelse(
        training_data$timedelta == Inf,
        0,
        as.integer(training_data$timedelta > 3600)
    )
    training_data$training_session_idx <- cumsum(training_data$training_session_inc)

    tmp_first_day <- data.frame(dplyr::summarise(
        dplyr::group_by(training_data, PID),
        first_day = min(training_session_idx)
    ))

    training_data <- dplyr::left_join(training_data, tmp_first_day, c("PID"))
    training_data$training_session_idx <- training_data$training_session_idx - training_data$first_day

    # Compute level attempt idx's
    is_not_first_row <- is.na(lag(training_data$training_session_idx))
    is_repeated_pid <- training_data$PID != lag(training_data$PID)
    training_data$level_attempt_idx <- ifelse(
        is_not_first_row | is_repeated_pid | is.na(dplyr::lag(training_data$LevelAttemptGuid)),
        1,
        training_data$LevelAttemptGuid != dplyr::lag(training_data$LevelAttemptGuid)
    )
    training_data$level_attempt_idx <- cumsum(training_data$level_attempt_idx)

    # trunc file extension from stimulus column
    training_data$stimulus <- sub("\\..*", "", training_data$Stimulus)

    # parse speaker/phrase from stimulus filename
    stimuli_info <- data.frame(do.call("rbind", strsplit(training_data$stimulus, "-")))
    training_data$speaker <- stimuli_info$X1
    training_data$phrase <- stimuli_info$X2

    # configure data types
    training_data <- within(training_data, {
        pid <- as.factor(PID)
        stimulus <- as.factor(stimulus)
        speaker <- as.factor(speaker)
    })
    training_data <- merge(training_data, training_lexicon, by = "stimulus", all.x = TRUE)
    training_data <- training_data[order(training_data$pid, training_data$Timestamp), ]

    # clear unneeded columns
    training_data <- subset(training_data, select = c(
        Timestamp, datetime, pid, stimulus, Ok, speaker, phrase.y,
        training_session_idx, level_attempt_idx, LevelAttemptGuid
    ))
    training_data <- dplyr::rename(training_data, phrase = phrase.y)

    # Count exposures by VTT file
    exposure_counts_by_stimulus <- data.frame(dplyr::summarise(
        dplyr::group_by(training_data, pid, stimulus, phrase),
        stimulusExposures = sum(Ok)
    ))

    write.csv(exposure_counts_by_stimulus, "analysis-output/exposure_counts_by_stimulus.csv")

    # Count exposures by phrase (each phrase has 4 VTT files)
    exposure_counts_by_phrase <- data.frame(dplyr::summarise(
        dplyr::group_by(training_data, pid, phrase),
        phraseExposures = dplyr::n()
    ))

    write.csv(exposure_counts_by_phrase, "analysis-output/exposure_counts_by_phrase.csv")

    # Count how many total words each participant received
    traing_word_exposures <- data.frame(dplyr::summarise(
        dplyr::group_by(training_data, pid),
        training_word_exposures = sum(Ok)
    ))

    # Given how many of which stimuli each participant was exposed to,
    # calculate how many times each pid was exposed to each phoneme
    exposure_counts_by_phoneme <- merge(exposure_counts_by_stimulus, training_lexicon, by = "stimulus", all.x = TRUE)
    exposure_counts_by_phoneme <- dplyr::rename(exposure_counts_by_phoneme, phrase = phrase.y)

    # validity checking
    missing_pronounciations <- is.na(exposure_counts_by_phoneme$pronounciation)
    words_not_in_lexicon <- exposure_counts_by_phoneme[missing_pronounciations, ]
    if (nrow(words_not_in_lexicon) > 0) {
        print("### ASSERT FAILED: ###")
        print("Words not in the lexicon:")
        print(words_not_in_lexicon$word)
    }
    pronounciation_counts <- data.frame(dplyr::summarise(
        dplyr::group_by(training_lexicon, phrase),
        pronounciations = dplyr::n()
    ))
    pronounciation_counts <- dplyr::filter(pronounciation_counts, pronounciations != 4)
    if (nrow(pronounciation_counts) > 0) {
        print("### ASSERT FAILED: ###")
        print("Words with invalid pronounciation counts")
        print(pronounciation_counts)
    }

    exposure_counts_by_phoneme <- dplyr::mutate(exposure_counts_by_phoneme, across(AA:ZH, ~ .x * stimulusExposures))
    write.csv(exposure_counts_by_phoneme, "analysis-output/exposure_counts_by_phoneme_0.csv")

    p_exposures <- tidyr::gather(exposure_counts_by_phoneme, phoneme, phoneme_exposures, AA:ZH)
    p_exposures$phoneme <- as.factor(p_exposures$phoneme)
    p_exposures <- data.frame(dplyr::summarise(
        dplyr::group_by(p_exposures, pid, phoneme),
        phoneme_exposures = sum(phoneme_exposures)
    ))

    write.csv(p_exposures, "analysis-output/exposure_counts_by_phoneme.csv")

    # Cleanup
    rm(idx)
    rm(tmp_df)
    rm(training_files)
    rm(tmp_first_day)
    rm(stimuli_info)
    rm(exposure_counts_by_stimulus)
    rm(words_not_in_lexicon)
    rm(pronounciation_counts)
    rm(exposure_counts_by_phoneme)
    rm(is_repeated_pid)
    rm(is_not_first_row)
    rm(missing_pronounciations)
```

## Training Reports
```{r create-training-reports, echo = FALSE}
    training_day_summary <- data.frame(dplyr::summarise(
        dplyr::group_by(training_data, pid, training_session_idx),
        startTime = min(datetime),
        stopTime = max(datetime),
        phraseStimCount = sum(Ok),
        durationInM = 60 * as.double(difftime(max(datetime), min(datetime), units = "hours"))
    ))

    stims_per_level <- data.frame(dplyr::summarise(
        dplyr::group_by(training_data, pid, LevelAttemptGuid),
        levelStartTime = min(Timestamp),
        stimCount = sum(Ok)
    ))

    uniq_phrases <- data.frame(dplyr::summarise(
        dplyr::group_by(exposure_counts_by_phrase, pid),
        uniquePhrases = dplyr::n(),
        phrases = paste(phrase, collapse = "|")
    ))

    total_p_exposures_by_pid <- data.frame(dplyr::summarise(
        dplyr::group_by(p_exposures, pid),
        totalPhonemeExposures = sum(phoneme_exposures),
        meanPhonemeExposures = mean(phoneme_exposures),
        stdevPhonemeExposures = sd(phoneme_exposures)
    ))

    untrained_phones <- data.frame(dplyr::summarise(
        dplyr::group_by(dplyr::filter(p_exposures, phoneme_exposures == 0), pid),
        untrainedPhones = paste(phoneme, collapse = "|")
    ))

    training_report <- data.frame(dplyr::summarise(
        dplyr::group_by(training_data, pid),
        first_day = min(datetime),
        lastDay = max(datetime),
        uniqueSessions = max(training_session_idx)+1,
        dateRange = as.integer(max(datetime) - min(datetime)),
        totalPhraseStimExposures = sum(Ok)
    ))

    training_day_summary_by_pid <- data.frame(dplyr::summarise(
        dplyr::group_by(training_day_summary, pid),
        meantrainingSessionDurationM = mean(durationInM)
    ))

    level_attempts_by_pid <- data.frame(dplyr::summarise(
        dplyr::group_by(stims_per_level, pid),
        levelAttempts = dplyr::n()
    ))

    training_report <- merge(training_report, level_attempts_by_pid, by = "pid", keep.x = TRUE)
    training_report <- merge(training_report, training_day_summary_by_pid, by = "pid", keep.x = TRUE)
    training_report$level_attempts_per_session <- training_report$levelAttempts / training_report$uniqueSessions
    training_report <- merge(training_report, total_p_exposures_by_pid, by = "pid", keep.x = TRUE)
    training_report <- merge(training_report, untrained_phones, by = "pid", keep.x = TRUE)
    training_report <- merge(training_report, uniq_phrases, by = "pid", keep.x = TRUE)

    write.csv(training_report, "analysis-output/training_report.csv")

    # Cleanup
    rm(training_day_summary)
    rm(stims_per_level)
    rm(uniq_phrases)
    rm(total_p_exposures_by_pid)
    rm(untrained_phones)
    rm(training_day_summary_by_pid)
    rm(level_attempts_by_pid)
```

# PHONEMES
## Load data
```{r load-phoneme-data, echo = FALSE}
    phone_df <- load_eval_files("_phonemes_")
    phone_df <- merge_eval_files_with_training(phone_df, traing_word_exposures)

    phone_df <- within(phone_df, {
        speaker_gender <- as.factor(toupper(substring(stimfile, 1, 1)))
        stimfile <- as.factor(stimfile)
    })

    # Manually check ratios
    summary(phone_df$correct)
    table(phone_df$pid, phone_df$correct, phone_df$condition)
    table(phone_df$pid, phone_df$correct)
    table(phone_df$condition, phone_df$correct)

    phone_df_with_phone_exposures <- merge(
        phone_df, phone_translate,
        by.x = "stimulus", by.y = "test_word",
        keep.x = TRUE
    )

    phone_df_with_phone_exposures <- dplyr::left_join(
        phone_df_with_phone_exposures,
        p_exposures,
        c("train_phone" = "phoneme", "pid")
    )
    phone_df_with_phone_exposures$train_phone <- as.factor(phone_df_with_phone_exposures$train_phone)

    # Question: Should control group training predictors be converted from NA to 0??
    phone_df_with_phone_exposures$phoneme_exposures <- replace(
        phone_df_with_phone_exposures$phoneme_exposures,
        is.na(phone_df_with_phone_exposures$phoneme_exposures),
        0
    )

    # normalize phoneme exposure counts
    phoneme_exposures <- phone_df_with_phone_exposures$phoneme_exposures
    phone_df_with_phone_exposures$phoneme_exposures_n <- phoneme_exposures / max(phoneme_exposures, na.rm = TRUE)

    ordered_phones <- phone_translate[order(phone_translate$phone_type, phone_translate$test_phone), ]$test_phone
    ordered_phones <- stringi::stri_remove_empty(ordered_phones)
    phone_df_with_phone_exposures <- within(phone_df_with_phone_exposures, {test_phone <- factor(
        test_phone,
        levels = ordered_phones,
        labels = ordered_phones
    )})
```

## Explore and visualize ðŸ“ˆ
```{r plot-phoneme-data, echo = FALSE}
    post_test_summary_by_condition <- data.frame(
        dplyr::summarise(
            dplyr::group_by(phone_df_with_phone_exposures, group, condition),
            correctPortion = mean(correct),
            se = sd(correct) / sqrt(length(correct))
        )
    )

    dodge <- ggplot2::position_dodge(width = 0.25)

    ggplot2::ggplot(post_test_summary_by_condition, ggplot2::aes(
        x = condition, y = correctPortion,
        group = group, color = group, shape = group
    )) +
        ggplot2::geom_hline(yintercept = 1 / 9, linetype = "dashed", color = "gray") +
        ggplot2::geom_line(position = dodge) +
        ggplot2::geom_point(position = dodge, size = 4) +
        ggplot2::geom_errorbar(
            ggplot2::aes(ymin = correctPortion - se, ymax = correctPortion + se),
            position = dodge,
            width = .125,
            color = "#555555"
        ) +
        ggplot2::scale_y_continuous(labels = scales::percent, limits = c(0, 1.0)) +
        ggplot2::labs(
            x = "Test Session",
            y = "Portion Correct",
            title = "Phoneme Identification Before and After Training Period",
            color = "Group", shape = "Group"
        ) +
        ggplot2::theme_classic() +
        ggplot2::theme(
            legend.position = c(0.80, 0.85),
            legend.background = ggplot2::element_rect(size = 0.5, color = "#888888", fill = "#EEEEEE")
        ) +
        ggthemes::scale_color_colorblind()

    save_plot()

    phone_exp_post_only <- dplyr::filter(
        phone_df_with_phone_exposures,
        group == "Experimental" & condition == "Post-test"
    )

    post_test_summary_by_pid <- data.frame(
        dplyr::summarise(
            dplyr::group_by(phone_exp_post_only, pid, group, phone_type, test_phone),
            correctPortion = mean(correct),
            phoneme_exposures = mean(phoneme_exposures),
            se = sd(correct) / sqrt(length(correct))
        )
    )

    ggplot2::ggplot(post_test_summary_by_pid, ggplot2::aes(
        x = phoneme_exposures, y = correctPortion,
        label = test_phone, color = phone_type
    )) +
        ggplot2::facet_wrap(facets = ggplot2::vars(pid)) +
        ggplot2::geom_hline(yintercept = 1 / 9, linetype = "dashed", color = "gray") +
        ggplot2::geom_text(size = 3) +
        ggplot2::scale_y_continuous(labels = scales::percent, limits = c(0, 1.0)) +
        ggplot2::labs(
            color = "Phone type",
            x = "Phoneme Exposures",
            y = "Portion Correct",
            title = "(Individual's) Effect of Stimulus Exposures on Phoneme Identification"
        ) +
        ggplot2::theme_classic() +
        ggplot2::theme(
            legend.position = c(0.85, 0.2),
            legend.background = ggplot2::element_rect(size = 0.5, color = "#888888", fill = "#EEEEEE")
        ) +
        ggthemes::scale_color_colorblind()

    save_plot(width = 12)


    post_test_summary_by_phone <- data.frame(
        dplyr::summarise(
            dplyr::group_by(phone_exp_post_only, phone_type, test_phone),
            correctPortion = mean(correct),
            phoneme_exposures = mean(phoneme_exposures),
            se = sd(correct) / sqrt(length(correct))
        )
    )

    ggplot2::ggplot(post_test_summary_by_phone, ggplot2::aes(
        x = phoneme_exposures, y = correctPortion,
        label = test_phone, color = phone_type
    )) +
        ggplot2::geom_hline(yintercept = 1 / 9, linetype = "dashed", color = "gray") +
        ggplot2::geom_text(size = 3) +
        ggplot2::scale_y_continuous(labels = scales::percent, limits = c(0, 1.0)) +
        ggplot2::labs(
            color = "Phone Type",
            x = "Phoneme Exposures",
            y = "Portion Correct",
            title = "Effect of Stimulus Exposures on Phoneme Identification"
        ) +
        ggplot2::theme_classic() +
        ggplot2::theme(
            legend.position = c(0.8, 0.85),
            legend.background = ggplot2::element_rect(size = 0.5, color = "#888888", fill = "#EEEEEE")
        ) +
        ggthemes::scale_color_colorblind()

    save_plot()
```

```{r plot-phoneme-data2, include = FALSE}
    # extra plots

    # Consonants vs vowels
    post_test_summary_by_type <- data.frame(
        dplyr::summarise(
            dplyr::group_by(phone_df_with_phone_exposures, group, phone_type),
            correctPortion = mean(correct),
            phoneme_exposures = mean(phoneme_exposures),
            se = sd(correct) / sqrt(length(correct))
        )
    )

    ggplot2::ggplot(post_test_summary_by_type, ggplot2::aes(
        x = phone_type, y = correctPortion,
        label = phone_type, fill = group
    )) +
        ggplot2::geom_hline(yintercept = 1 / 9, linetype = "dashed", color = "gray") +
        ggplot2::geom_bar(stat = "identity", , position = ggplot2::position_dodge()) +
        ggplot2::scale_y_continuous(labels = scales::percent, limits = c(0, 1.0)) +
        ggplot2::labs(
            fill = "Group",
            x = "Phoneme Exposures",
            y = "Portion Correct",
            title = "Post-test Phoneme Identification Group Comparison"
        ) +
        ggplot2::theme_classic() +
        ggplot2::theme(
            legend.position = c(0.8, 0.85),
            legend.background = ggplot2::element_rect(size = 0.5, color = "#888888", fill = "#EEEEEE")
        ) +
        ggthemes::scale_fill_colorblind()

    save_plot()

    post_test_summary_by_group <- data.frame(
        dplyr::summarise(
            dplyr::group_by(phone_df_with_phone_exposures, group, phone_type, test_phone),
            correctPortion = mean(correct),
            phoneme_exposures = mean(phoneme_exposures),
            se = sd(correct) / sqrt(length(correct))
        )
    )

    ggplot2::ggplot(post_test_summary_by_group, ggplot2::aes(
        x = test_phone, y = correctPortion,
        label = test_phone, fill = group
    )) +
        ggplot2::geom_hline(yintercept = 1 / 9, linetype = "dashed", color = "gray") +
        ggplot2::geom_bar(stat = "identity", , position = ggplot2::position_dodge()) +
        ggplot2::scale_y_continuous(labels = scales::percent, limits = c(0, 1.0)) +
        ggplot2::labs(
            fill = "Group",
            x = "Phoneme Exposures",
            y = "Portion Correct",
            title = "Post-test Phoneme Identification (by phoneme)"
        ) +
        ggplot2::theme_classic() +
        ggplot2::theme(
            legend.position = c(0.8, 0.85),
            legend.background = ggplot2::element_rect(size = 0.5, color = "#888888", fill = "#EEEEEE")
        ) +
        ggthemes::scale_fill_colorblind()

    save_plot()

```

## Model
```{r model-phoneme-data, echo = FALSE}

    phone_m0 <- glm(correct ~ 1, data = phone_df_with_phone_exposures, family = "binomial")

    phone_m0.0 <- bin_lme(
        data = phone_df_with_phone_exposures,
        formula = correct ~ 1
            + (1 | pid)
    )

    anova(phone_m0.0, phone_m0) # 0.0 not different

    phone_m0.1 <- bin_lme(
        data = phone_df_with_phone_exposures,
        formula = correct ~ 1
            + (1 | phone_type / test_phone)
    )

    anova(phone_m0.1, phone_m0) # 0.1 is different

    phone_m0.2 <- bin_lme(
        data = phone_df_with_phone_exposures,
        formula = correct ~ 1
            + (1 | phone_type / test_phone)
            + (1 | pid)
    )
    anova(phone_m0.1, phone_m0, phone_m0.2) # not different

    phone_m0.3 <- bin_lme(
        data = phone_df_with_phone_exposures,
        formula = correct ~ condition * group
            + (1 | phone_type / test_phone)
    )
    anova(phone_m0.1, phone_m0, phone_m0.3) # not different

    phone_m0.4 <- bin_lme(
        data = phone_df_with_phone_exposures,
        formula = correct ~ condition * group
            + (1 + condition | phone_type / test_phone)
            + (1 + group | phone_type / test_phone)
    )
    anova(phone_m0.1, phone_m0, phone_m0.4) # not different
    summary(phone_m0.4)

    # conclusion: no significant interaction between group and test session


    ggplot2::ggplot(data = phone_df_with_phone_exposures, ggplot2::aes(x = condition, y = correct, color = group)) +
        ggplot2::geom_point(
            alpha = 0.25,
            position = ggplot2::position_jitter(width = .2, height = 0.05),
        ) +
        ggplot2::labs(
            x = "Testing Session",
            y = ggplot2::element_blank(),
            title = "Phoneme Trials before and after training (logistic) Trials",
            color = "Group"
        ) +
        ggplot2::scale_y_continuous(breaks = c(0.0, 1.0), labels = c("Incorrect", "Correct")) +
        ggplot2::theme(
            legend.position = c(0.9, 0.5),
            panel.grid.minor.y = ggplot2::element_blank()
        ) +
        ggthemes::scale_color_colorblind()

    save_plot(width=12)



    # Examine effect of # of phoneme exposures
    exp_post_only <- dplyr::filter(phone_df_with_phone_exposures, group == "Experimental", condition == "Post-test")
    phone_m1 <- glm(correct ~ 1, data = exp_post_only, family = "binomial")

    phone_m1.0 <- bin_lme(
        data = exp_post_only,
        formula = correct ~ 1
            + (1 | pid)
    )
    anova(phone_m1.0, phone_m1) # not different

    phone_m1.1 <- bin_lme(
        data = exp_post_only,
        formula = correct ~ 1
            + (1 | phone_type / test_phone)
    )

    anova(phone_m1.1, phone_m1) # is different!

    phone_m1.2 <- bin_lme(
        data = exp_post_only,
        formula = correct ~ phoneme_exposures_n
            + (phoneme_exposures_n | phone_type / test_phone)
    )

    anova(phone_m1.2, phone_m1.1, phone_m1) # is not different
    # conclude: no effect of exposures

    ggplot2::ggplot(data = exp_post_only, ggplot2::aes(x = phoneme_exposures, y = correct, color = phone_type)) +
        ggplot2::geom_point(
            alpha = 0.25,
            position = ggplot2::position_jitter(width = 100, height = 0.05),
        ) +
        ggplot2::labs(
            x = "Phoneme Exposures",
            y = ggplot2::element_blank(),
            title = "Post-training Phoneme Identification Trials",
            color = "Phoneme Type"
        ) +
        ggplot2::scale_y_continuous(breaks = c(0.0, 1.0), labels = c("Incorrect", "Correct")) +
        ggplot2::theme(
            legend.position = c(0.9, 0.5),
            panel.grid.minor.y = ggplot2::element_blank()
        ) +
        ggthemes::scale_color_colorblind()

    save_plot(width=12)
```

# PROSODY
## Load Data
```{r load-prosody-data, echo = FALSE}
    prosody_df <- load_eval_files("_prosody_")
    prosody_df <- merge_eval_files_with_training(prosody_df, traing_word_exposures)

    prosody_df <- tidyr::separate(
        data = prosody_df, col = stimfile,
        into = "sentence_id",
        sep = "_",
        extra = "drop",
        remove = FALSE
    )
    type_starts_with_f <- substring(prosody_df$stimfile, 1, 1) == "f"
    prosody_df$prosody_type <- as.factor(ifelse(type_starts_with_f, "Focus", "Phrase"))
    prosody_df$stimfile <- as.factor(prosody_df$stimfile)

    focus_df <- dplyr::filter(prosody_df, prosody_df$prosody_type == "Focus")
    focus_df$sentence_id <- as.factor(focus_df$sentence_id)

    phrase_df <- dplyr::filter(prosody_df, prosody_df$prosody_type == "Phrase")
    phrase_df$sentence_id <- as.factor(phrase_df$sentence_id)

    # cleanup
    rm(type_starts_with_f)
```

## Plot Focus Discrimination
```{r plot-focus-data, echo = FALSE}

    focus_test_session_comparison_by_group <- dplyr::summarise(
        dplyr::group_by(focus_df, group, condition),
        correctPortion = mean(correct),
        se = sd(correct) / sqrt(length(correct))
    )

    dodge <- ggplot2::position_dodge(width = 0.125)

    ggplot2::ggplot(focus_test_session_comparison_by_group, ggplot2::aes(
        x = condition, y = correctPortion,
        group = group, color = group, shape = group
    )) +
        ggplot2::geom_hline(yintercept = .5, linetype = "dashed", color = "gray") +
        ggplot2::geom_line(position = dodge) +
        ggplot2::geom_point(position = dodge, size = 4) +
        ggplot2::geom_errorbar(
            ggplot2::aes(ymin = correctPortion - se, ymax = correctPortion + se),
            position = dodge,
            width = .125,
            color = "#555555"
        ) +
        ggplot2::scale_y_continuous(labels = scales::percent, limits = c(0, 1.0)) +
        ggplot2::labs(
            x = "Test Session",
            y = "Portion Correct",
            title = "Focus Discrimination Before and After Training",
            color = "Group", shape = "Group"
        ) +
        ggplot2::theme_classic() +
        ggplot2::theme(
            legend.position = c(0.8, 0.85),
            legend.background = ggplot2::element_rect(size = 0.5, color = "#888888", fill = "#EEEEEE")
        ) +
        ggthemes::scale_color_colorblind()

    save_plot()

    focus_post_experimental_only <- dplyr::filter(focus_df, group == "Experimental", condition == "Post-test")

    focus_post_experimental_only_summary <- dplyr::summarise(
        dplyr::group_by(focus_post_experimental_only, pid, training_word_exposures),
        correctPortion = mean(correct),
        color = as.factor(1),
        se = sd(correct) / sqrt(length(correct))
    )

    ggplot2::ggplot(focus_post_experimental_only_summary, ggplot2::aes(
        x = training_word_exposures, y = correctPortion
    )) +
        ggplot2::geom_hline(yintercept = .5, linetype = "dashed", color = "gray") +
        ggplot2::geom_point(ggplot2::aes(color = color), size = 3, show.legend = FALSE) +
        ggplot2::geom_errorbar(
            ggplot2::aes(ymin = correctPortion - se, ymax = correctPortion + se),
            color = "#555555"
        ) +
        ggplot2::scale_y_continuous(labels = scales::percent, limits = c(0, 1.0)) +
        ggplot2::xlim(0, NA) +
        ggplot2::labs(
            x = "Training Word Exposures",
            y = "Portion Correct",
            title = "Word Exposure Effect on Focus Discrimination"
        )

    save_plot()
```

## Focus - Model & Test
```{r model-focus-data, echo = FALSE}
    focus_model <- function(formula) bin_lme(formula = formula, data = focus_df)

    focus_m0 <- glm(data = focus_df, formula = correct ~ 1, family = "binomial")

    focus_m0.1 <- bin_lme(
        data = focus_df,
        formula = correct ~ 1
            + (1 | sentence_id / stimulus)
    )
    anova(focus_m0.1, focus_m0)

    focus_m0.2 <- bin_lme(
        data = focus_df,
        formula = correct ~ 1
            + (1 | pid)
    )
    anova(focus_m0.2, focus_m0)

    # conclude - random effects are unimportant

    focus_m0.3 <- glm(
        data = focus_df, family = "binomial",
        formula = correct ~ group * condition
    )

    summary(focus_m0.3)


    # conclude - no different between groups or testing session

    focus_df_exp_post_test_only <- dplyr::filter(focus_df, condition == "Post-test", group == "Experimental")

    focus_m1 <- glm(data = focus_df_exp_post_test_only, formula = correct ~ 1, family = "binomial")

    focus_m1.0 <- bin_lme(
        data = focus_df_exp_post_test_only,
        formula = correct ~ 1
            + (1 | sentence_id / stimulus)
    )

    anova(focus_m1.0, focus_m1) # not different

    focus_m1.1 <- bin_lme(
        data = focus_df_exp_post_test_only,
        formula = correct ~ 1
            + (1 | pid)
    )
    anova(focus_m1.1, focus_m1) # not different

    # conclude - random effects do not add value

    focus1.2 <- glm(data = focus_df_exp_post_test_only, formula = correct ~ training_word_exposures_n, family = "binomial")
    summary(focus1.2)

    # conclude - no training effect

    ggplot2::ggplot(
        focus_df_exp_post_test_only,
        ggplot2::aes(x = training_word_exposures, y = correct)
    ) +
        ggplot2::geom_point(
            color = theme_colors[1],
            position = ggplot2::position_jitter(width = 500, height = 0.05),
            alpha = 0.1
        ) +
        ggplot2::labs(
            x = "Training Word Exposures",
            y = ggplot2::element_blank(),
            title = "Post-training Focus Discrimination Trials"
        ) +
        ggplot2::scale_y_continuous(breaks = c(0.0, 1.0), labels = c("Incorrect", "Correct"))

    save_plot()
```

## Plot Phrase Discrimination
```{r plot-phrase-data, echo = FALSE}

    phrase_test_session_by_group <- dplyr::summarise(
        dplyr::group_by(phrase_df, group, condition),
        correctPortion =  mean(correct),
        se = sd(correct) / sqrt(length(correct))
    )

    dodge <- ggplot2::position_dodge(width = 0.125)

    ggplot2::ggplot(phrase_test_session_by_group, ggplot2::aes(
        x = condition, y = correctPortion,
        group = group, color = group, shape = group
    )) +
        ggplot2::geom_hline(yintercept = .5, linetype = "dashed", color = "gray") +
        ggplot2::geom_line(position = dodge) +
        ggplot2::geom_point(position = dodge, size = 4) +
        ggplot2::geom_errorbar(
            ggplot2::aes(ymin = correctPortion - se, ymax = correctPortion + se),
            position = dodge,
            width = .125,
            color = "#555555"
        ) +
        ggplot2::scale_y_continuous(labels = scales::percent, limits = c(0, 1.0)) +
        ggplot2::labs(
            x = "Test Session",
            y = "Portion Correct",
            title = "Phrase Discrimination Before and After Training",
            color = "Group", shape = "Group"
        ) +
        ggplot2::theme_classic() +
        ggplot2::theme(
            legend.position = c(0.80, 0.85),
            legend.background = ggplot2::element_rect(size = 0.5, color = "#888888", fill = "#EEEEEE")
        ) +
        ggthemes::scale_color_colorblind()

    save_plot()

    phrase_post_exp_only <- dplyr::filter(phrase_df, group == "Experimental", condition == "Post-test")

    phrase_post_exp_only_summary <- dplyr::summarise(
        dplyr::group_by(phrase_post_exp_only, pid, training_word_exposures),
        color = as.factor(1),
        correctPortion = mean(correct),
        se = sd(correct) / sqrt(length(correct))
    )

    ggplot2::ggplot(phrase_post_exp_only_summary, ggplot2::aes(
        x = training_word_exposures, y = correctPortion
    )) +
        ggplot2::geom_hline(yintercept = 0.5, linetype = "dashed", color = "gray") +
        ggplot2::geom_point(ggplot2::aes(color = color), size = 3, show.legend = FALSE) +
        ggplot2::geom_errorbar(
            ggplot2::aes(ymin = correctPortion - se, ymax = correctPortion + se),
            position = dodge,
            color = "#555555"
        ) +
        ggplot2::scale_y_continuous(labels = scales::percent, limits = c(0, 1.0)) +
        ggplot2::xlim(0, NA) +
        ggplot2::labs(
            x = "Training Word Exposures",
            y = "Portion Correct",
            title = "Word Exposure Effect on Phrase Boundary Discrimination"
        ) +
        ggplot2::theme_classic()

    save_plot()
```

## Phrase Boundary - Model & Test
```{r model-phrase-data, echo = FALSE}
    phrase_m0 <- glm(data = phrase_df, formula = correct ~ 1, family = "binomial")

    phrase_m0.0 <- bin_lme(
        data = phrase_df,
        formula = correct ~ 1
            + (1|sentence_id / stimulus)
    )

    anova(phrase_m0.0, phrase_m0) # not different

    phrase_m0.1 <- bin_lme(
        data = phrase_df,
        formula = correct ~ 1
            + (1|pid)
    )

    anova(phrase_m0.1, phrase_m0) # not different

    # conclude - random effects do not contribute to the model

    phrase_m0.2 <- glm(
        data = phrase_df,
        family = "binomial",
        formula = correct ~ group * condition
    )

    summary(phrase_m0.2)
    # conclude - no effect between groups or between pre/post test sessions

    phrase_m1 <- glm(data = phrase_post_exp_only, formula = correct ~ 1, family = "binomial")

    phrase_m1.1 <- bin_lme(
        data = phrase_post_exp_only,
        formula = correct ~ 1
            + (1|sentence_id / stimulus)
    )

    anova(phrase_m1.1, phrase_m1) # not different

    phrase_m1.2 <- bin_lme(
        data = phrase_post_exp_only,
        formula = correct ~ 1
            + (1|pid)
    )

    anova(phrase_m1.2, phrase_m1) # not different

    # conclude - random effects do not contribute

    phrase_m1.3 <- glm(
        data = phrase_post_exp_only,
        family = "binomial",
        formula = correct ~ training_word_exposures_n
    )

    anova(phrase_m1.3, phrase_m1) # not different

    ggplot2::ggplot(
        phrase_post_exp_only,
        ggplot2::aes(x = training_word_exposures, y = correct)
    ) +
        ggplot2::geom_point(
            color = theme_colors[1],
            position = ggplot2::position_jitter(width = 500, height = 0.05),
            alpha = 0.1,
            show.legend = FALSE
        ) +
        ggplot2::labs(
            x = "Training Word Exposures",
            y = ggplot2::element_blank(),
            title = "Post-training Phrase Discrimination Trials"
        ) +
        ggplot2::scale_y_continuous(breaks = c(0.0, 1.0), labels = c("Incorrect", "Correct"))

    save_plot()
```

# INTEGRATION
## Load Data
```{r load-integration-data, echo = FALSE}
    integration_df <- load_eval_files("_integration_", create_correct_column = FALSE)
    integration_df <- merge_eval_files_with_training(integration_df, traing_word_exposures)

    integration_df <- within(integration_df, {
        integrated <- 1 - as.integer(mapply(grepl, pattern = selection, x = stimulus))
        auditory_stim <- as.factor(substring(stimulus, 1, 2))
        tactile_stim <- as.factor(substring(stimulus, 4, 5))
        speaker <- as.integer(substring(audibleFile, 8, 9))
        speaker_gender <- as.factor(substring(stimfile, 1, 1))
        train_phone <- as.factor(substring(stimulus, 4, 4))
    })
    integration_df$selected_auditory <- as.character(integration_df$selection) == as.character(integration_df$auditory_stim)

    integration_df <- merge(
        integration_df, p_exposures,
        by.x = c("pid", "train_phone"), by.y = c("pid", "phoneme"),
        keep.X = FALSE, all.x = TRUE
    )

    integration_df$phoneme_exposures <- replace(
        integration_df$phoneme_exposures,
        is.na(integration_df$phoneme_exposures),
        0
    )
    integration_df$phoneme_exposures_n <- integration_df$phoneme_exposures / max(integration_df$phoneme_exposures, na.rm = TRUE)

    write.csv(integration_df, 'analysis-output/integration.csv')
```

## Explore & Visualize ðŸ“ˆ
```{r plot-integration-data, echo = FALSE}
    integration_by_audible_file <- dplyr::summarise(
        dplyr::group_by(dplyr::filter(integration_df, condition == 'Pre-test'), audibleFile),
        auditory_selection_portion = mean(selected_auditory),
        se = sd(selected_auditory) / sqrt(length(selected_auditory))
    )
    integration_by_audible_file <- dplyr::arrange(integration_by_audible_file, auditory_selection_portion)

    # remove hard to understand auditory stim
    integration_df <- dplyr::filter(integration_df, audibleFile != "m_Pa_TK07.wav" & audibleFile != "f_Pa_TK03.wav" & audibleFile != "f_Ma_TK02.wav")

    integration_summary <- dplyr::summarise(
        dplyr::group_by(integration_df, group, condition),
        correctPortion =  mean(integrated),
        se = sd(integrated) / sqrt(length(integrated)),
        training_word_exposures = mean(training_word_exposures),
    )

    ggplot2::ggplot(integration_summary, ggplot2::aes(
        x = condition, y = correctPortion,
        group = group, color = group, shape = group,
    )) +
        ggplot2::geom_hline(yintercept = 0, linetype = "dashed", color = "gray") +
        ggplot2::geom_line(position = dodge) +
        ggplot2::geom_point(position = dodge, size = 4) +
        ggplot2::geom_errorbar(
            ggplot2::aes(ymin = correctPortion - se, ymax = correctPortion + se),
            position = dodge,
            width = .125,
            color = "#555555"
        ) +
        ggplot2::scale_y_continuous(labels = scales::percent, limits = c(0, 1.0)) +
        ggplot2::labs(
            x = "Test Session",
            y = "Portion Integrated",
            title = "Perceptual Integration Before and After Training",
            color = "Group", shape = "Group"
        ) +
        ggplot2::theme_classic() +
        ggplot2::theme(
            legend.position = c(0.8, 0.85),
            legend.background = ggplot2::element_rect(size = 0.5, color = "#888888", fill = "#EEEEEE")
        ) +
        ggthemes::scale_color_colorblind()

    save_plot()

    integration_post_exp_only <- dplyr::filter(integration_df, group == "Experimental", condition == "Post-test")

    integration_post_exp_only_summary <- dplyr::summarise(
        dplyr::group_by(integration_post_exp_only, pid, tactile_stim, training_word_exposures, phoneme_exposures, phoneme_exposures_n),
        integratedPortion = mean(integrated),
        se = sd(integrated) / sqrt(length(integrated))
    )

    ggplot2::ggplot(integration_post_exp_only_summary, ggplot2::aes(
        x = phoneme_exposures, y = integratedPortion,
        label = tactile_stim
    )) +
        ggplot2::geom_hline(yintercept = 0, linetype = "dashed", color = "gray") +
        ggplot2::geom_errorbar(
            ggplot2::aes(ymin = integratedPortion - se, ymax = integratedPortion + se),
            color = "#555555", width = 100
        ) +
        ggplot2::geom_text(ggplot2::aes(color = pid), size = 3) +
        ggplot2::scale_y_continuous(labels = scales::percent, limits = c(NA, 1.0)) +
        ggplot2::xlim(0, NA) +
        ggplot2::labs(
            x = "Consonant Exposures in Training",
            y = "Portion Integrated",
            title = "Phoneme Exposure Effect on Perceptual Integration",
            color = "Participant"
        ) +
        ggplot2::theme_classic() +
        ggthemes::scale_color_colorblind() +
        ggplot2::theme(legend.position = c(0.50, 0.75), legend.direction = "horizontal")

    save_plot()
```

## Model & Test
```{r model-integration-data, echo = FALSE}

    integration_m0 <- glm(data = integration_df, formula = integrated ~ 1, family = "binomial")

    integration_m0.0 <- bin_lme(
        data = integration_df,
        formula = integrated ~ 1
            + (1|auditory_stim)
    )

    anova(integration_m0.0, integration_m0) # yes diff

    integration_m0.1 <- bin_lme(
        data = integration_df,
        formula = integrated ~ 1
            + (1|auditory_stim)
            + (1|tactile_stim)
    )

    anova(integration_m0.1, integration_m0.0, integration_m0) # no diff

    integration_m0.2 <- bin_lme(
        data = integration_df,
        formula = integrated ~ 1
            + (1|auditory_stim)
            + (1|pid)
    )

    anova(integration_m0.2, integration_m0.0, integration_m0) # yes diff

    integration_m0.3 <- bin_lme(
        data = integration_df,
        formula = integrated ~ group*condition
            + (group|auditory_stim)
            + (group|pid)
            + (condition|auditory_stim)
            + (condition|pid)
    )

    anova(integration_m0.3, integration_m0.2, integration_m0.1, integration_m0) # yes diff

    summary(integration_m0.3)

    # conclude - no interaction effect

    integration_m1 <- glm(data = integration_post_exp_only, formula = integrated ~ 1, family = "binomial")

    integration_m1.0 <- bin_lme(
        data = integration_post_exp_only,
        formula = integrated ~ 1
            + (1|auditory_stim)
    )

    anova(integration_m1.0, integration_m1) # no diff

    integration_m1.1 <- bin_lme(
        data = integration_post_exp_only,
        formula = integrated ~ 1
            + (1|tactile_stim)
    )

    anova(integration_m1.1, integration_m1) # no diff

    integration_m1.2 <- bin_lme(
        data = integration_post_exp_only,
        formula = integrated ~ 1
            + (1|pid)
    )

    anova(integration_m1.2, integration_m1) # yes diff

    integration_m1.3 <- bin_lme(
        data = integration_post_exp_only,
        formula = integrated ~ phoneme_exposures_n
            + (phoneme_exposures_n|pid)
    )

    anova(integration_m1.3, integration_m1.2, integration_m1) # no diff

```



# TRAINING PERFORMANCE (load data)
```{r load-training-data-words, echo = FALSE}

    setwd("../data/training/TrainingLogs")

    word_training_files <- list.files(".", "*.csv")
    word_training_df <- data.frame()

    for (idx in seq_along(word_training_files)) {
        tmp_df <- read.csv(word_training_files[idx])
        if (nrow(tmp_df) > 0) {
            word_training_df <- dplyr::bind_rows(word_training_df, tmp_df)
        }
    }
    setwd("../../../analysis")

    word_training_df <- within(word_training_df, {
        PID <- as.factor(PID)
        Level <- as.factor(Level)
        Stimulus <- as.factor(Stimulus)
        LevelAttemptGuid <- as.factor(LevelAttemptGuid)
    })


    word_training_df <- word_training_df[order(word_training_df$PID, word_training_df$Timestamp), ]

    # merge in training game name
    game_levels <- read.csv("../aux-data/game-levels.csv")
    game_levels$Level <- as.factor(game_levels$Level)
    game_levels$Game <- as.factor(game_levels$Game)

    word_training_df <- merge(
        word_training_df, game_levels,
        by.x = "Level", by.y = "Level",
        keep.x = FALSE
    )

    # remove trials that occur after perfection
    level_attempt_summary <- data.frame(
        dplyr::summarise(
            dplyr::group_by(word_training_df, PID, Level, LevelAttemptGuid, Game),
            CorrectCount = sum(Correct),
            IncorrectCount = dplyr::n() - sum(Correct),
            TrialCount = dplyr::n(),
            PercentageCorrect = mean(Correct),
            LevelCompleteTime = max(Timestamp),
            LevelAttemptPerfect = mean(Correct) == 1.0 && dplyr::n() >= 10
        )
    )
    # remove disingenuous attempts?

    # assign attempt idx
    level_attempt_summary <- dplyr::arrange(level_attempt_summary, PID, Level, LevelCompleteTime)
    level_attempt_summary <- data.frame(dplyr::mutate(
        dplyr::group_by(level_attempt_summary, PID, Level),
        attempt_idx = order(order(LevelCompleteTime)) - 1
    ))

    level_attempt_summary <- data.frame(dplyr::mutate(
        dplyr::group_by(level_attempt_summary, PID, Level),
        LastAttemptIdx = max(attempt_idx)
    ))
    level_attempt_summary$p_l_progression <- level_attempt_summary$attempt_idx / level_attempt_summary$LastAttemptIdx

    # determine which levels were the first perfects
    level_attempt_first_perfects <- data.frame(
        dplyr::summarise(
            dplyr::group_by(
                dplyr::filter(level_attempt_summary, LevelAttemptPerfect),
                PID,
                Level
            ),
            LevelPerfectedTimestamp = min(LevelCompleteTime)
        )
    )

    word_training_df <- merge(
        word_training_df, level_attempt_first_perfects,
        by.x = c("PID", "Level"), by.y = c("PID", "Level"),
        keep.x = FALSE, all.x = TRUE
    )

    word_training_df <- dplyr::filter(
        word_training_df,
        is.na(LevelPerfectedTimestamp) | Timestamp <= LevelPerfectedTimestamp
    )

    # break out the phrase
    stimuli_info <- data.frame(do.call("rbind", strsplit(as.character(word_training_df$Stimulus), "-")))

    word_training_df <- within(word_training_df, {
        pid <- as.factor(PID)
        stimulus <- as.factor(Stimulus)
        speaker <- as.factor(stimuli_info$X1)
        phrase <- as.factor(stimuli_info$X2)
        Game <- as.factor(Game)
    })

    word_training_df <- dplyr::arrange(word_training_df, pid, phrase, Timestamp)

    # add the exposures column
    word_training_df <- data.frame(dplyr::mutate(
        dplyr::group_by(word_training_df, PID, phrase),
        exposures = order(order(Timestamp))
    ))
    word_training_df <- data.frame(dplyr::mutate(
        dplyr::group_by(word_training_df, PID, phrase),
        totalExposures = max(exposures)
    ))

    word_training_df$exposure_progression <- (word_training_df$exposures-1) / (word_training_df$totalExposures-1)

    write.csv(word_training_df, 'analysis-output/word_exposures.csv')

    rm(idx)
    rm(tmp_df)
    rm(word_training_files)
    rm(stimuli_info)
```

# TRAINING PERFORMANCE by level
```{r training-perf-by-level, echo = FALSE}

    level_attempt_progression_summary <- tidyr::drop_na(level_attempt_summary, p_l_progression)
    write.csv(level_attempt_progression_summary, "analysis-output/level_attempt_progression_summary.csv")

    train_perf_m0 <- lm(
        data = level_attempt_progression_summary,
        weights = TrialCount,
        PercentageCorrect ~ 1,
    )

    train_perf_m0.1 <- lmerTest::lmer(
        data = level_attempt_progression_summary,
        weights = TrialCount,
        REML = FALSE,
        PercentageCorrect ~ 1
            + (1|Game/Level),
    )

    anova(train_perf_m0.1, train_perf_m0) # contributes

    train_perf_m0.2 <- lmerTest::lmer(
        data = level_attempt_progression_summary,
        weights = TrialCount,
        REML = FALSE,
        PercentageCorrect ~ 1
            + (1|Game/Level)
            + (1|PID),
    )

    anova(train_perf_m0.2, train_perf_m0.1, train_perf_m0) # contributes


    train_perf_m0.3 <- lmerTest::lmer(
        data = level_attempt_progression_summary,
        weights = TrialCount,
        REML = FALSE,
        PercentageCorrect ~ p_l_progression
            + (p_l_progression|Game/Level)
            + (p_l_progression|PID),
    )

    anova(train_perf_m0.3, train_perf_m0.2, train_perf_m0.1, train_perf_m0) # contributes

    summary(train_perf_m0.3)


    train_perf_m0.4 <- lm(
        data = level_attempt_progression_summary,
        weights = TrialCount,
        PercentageCorrect ~ p_l_progression
    )

    anova(train_perf_m0.3, train_perf_m0.4)

    plot_values <- ggeffects::ggpredict(train_perf_m0.3, "p_l_progression")

    ggplot2::ggplot(plot_values, ggplot2::aes(x = x, y = predicted)) +
        ggplot2::geom_line(color = theme_colors[2], show.legend = FALSE) +
        ggplot2::geom_ribbon(
            ggplot2::aes(
                ymin = conf.low,
                ymax = conf.high,
            ),
            alpha = .25,
            fill = theme_colors[2]
        ) +
        ggplot2::geom_point(
            mapping = ggplot2::aes(
                x = p_l_progression,
                y = PercentageCorrect,
                size = TrialCount,
            ),
            color = theme_colors[1],
            data = level_attempt_progression_summary,
            position = ggplot2::position_jitter(width=0.01, height=0.01),
            alpha = 0.1
        ) +
        ggplot2::labs(
            x = "Progression",
            y = "Correct Portion",
            title = "Training Performance"
        ) +
        ggplot2::scale_y_continuous(labels = scales::percent) +
        ggplot2::theme(legend.position = c(0.5, 0.02), legend.direction = "horizontal")

    save_plot()
```

# Phoneme exposures proportions
```{r phoneme-proportions, echo = FALSE}
    buckeye <- read.csv("../aux-data/buckeye-phone-frequencies.csv")
    buckeye <- dplyr::filter(buckeye, trainPhoneme != "")

    aggregated_exposures <- dplyr::summarise(
        dplyr::group_by(p_exposures, phoneme),
        frequency = sum(phoneme_exposures)
    )

    phoneme_exposure_comparison <- merge(buckeye, aggregated_exposures, by.x = "trainPhoneme", by.y = "phoneme")
    phoneme_exposure_comparison <- dplyr::summarise(
        dplyr::group_by(phoneme_exposure_comparison, trainPhoneme),
        expected = sum(phonemeExposures),
        observed = sum(frequency)
    )
    phoneme_exposure_comparison <- merge(phoneme_exposure_comparison, phone_translate, by.x = "trainPhoneme", by.y = "train_phone")

    phoneme_exposure_comparison$expected_p <- phoneme_exposure_comparison$expected / sum(phoneme_exposure_comparison$expected)
    phoneme_exposure_comparison$observed_p <- phoneme_exposure_comparison$observed / sum(phoneme_exposure_comparison$observed)

    chisq.test(
        x = phoneme_exposure_comparison$observed,
        p = phoneme_exposure_comparison$expected_p
    )

    # x2(37, 162120) = 37364, p < 0.01
    # conclude - exposures did not match proportions for conversational english

    ordered_phones <- dplyr::arrange(phoneme_exposure_comparison, expected_p)$trainPhoneme

    phone_exp_long <- data.frame(tidyr::gather(phoneme_exposure_comparison, key = "Distribution", value = "proportion", expected_p, observed_p))
    phone_exp_long$Distribution = ifelse(phone_exp_long$Distribution == "expected_p", "Conversational", "Trained")

    phone_exp_long$trainPhoneme <- factor(phone_exp_long$trainPhoneme, ordered_phones)
    phone_exp_long$Distribution <- factor(phone_exp_long$Distribution, c("Trained", "Conversational"))

    ggplot2::ggplot(
        phone_exp_long,
        ggplot2::aes(y = trainPhoneme, x = proportion, fill = Distribution),
    ) +
        ggplot2::geom_bar(stat = "identity", position = ggplot2::position_dodge()) +
        ggplot2::labs(
            x = "Proportion",
            y = "Phoneme",
            title = "Conversational vs Trained Phoneme Distribution"
        ) +
        ggplot2::theme(legend.position = c(0.8, 0.15)) +
        ggthemes::scale_fill_colorblind()

    save_plot()

    phone_exp_long$trainPhoneme <- factor(phone_exp_long$trainPhoneme, rev(ordered_phones))

    ggplot2::ggplot(
        phone_exp_long,
        ggplot2::aes(x = trainPhoneme, y = proportion, fill = Distribution),
    ) +
        ggplot2::geom_bar(stat = "identity", position = ggplot2::position_dodge()) +
        ggplot2::labs(
            y = "Proportion",
            x = "Phoneme",
            title = "Conversational vs Trained Phoneme Distribution - horizontal"
        ) +
        ggplot2::theme(legend.position = c(0.85, 0.8)) +
        ggthemes::scale_fill_colorblind()

    save_plot(width = 12)

    phoneme_exposure_comparison$relative_training <- phoneme_exposure_comparison$observed_p / phoneme_exposure_comparison$expected_p

    ggplot2::ggplot(
        phoneme_exposure_comparison,
        ggplot2::aes(x = trainPhoneme, y = relative_training, fill = phone_type),
    ) +
        ggplot2::geom_hline(yintercept = 1.0, linetype = "dashed", color = "gray") +
        ggplot2::geom_bar(stat = "identity", position = ggplot2::position_dodge()) +
        ggplot2::geom_text(
            ggplot2::aes(label = trainPhoneme, color = phone_type),
            nudge_y = .05 * sign(phoneme_exposure_comparison$relative_training),
            show.legend = FALSE
        ) +
        ggplot2::labs(
            fill = "Phone Type",
            y = "Proportion Difference vs Expected",
            x = "Phoneme",
            title = "Conversational vs Trained Phoneme Distribution - horizontal"
        ) +
        ggplot2::scale_y_continuous(labels = scales::percent) +
        ggplot2::theme(legend.position = c(0.85, 0.8)) +
        ggthemes::scale_fill_colorblind()

    save_plot(
        width = 12,
        theme_overrides = ggplot2::theme(
            axis.text.x = ggplot2::element_blank(),
            panel.grid.major.x = ggplot2::element_blank(),
            panel.grid.minor.x = ggplot2::element_blank(),
            axis.ticks.x = ggplot2::element_blank()
        )
    )
```

# END
