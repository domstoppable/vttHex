---
title: "Vibey Transcribey Results"
output: html_document
---

R code for processing vibey-transcribey data

Working directory should be `/software`

```{r load-helpers, include = FALSE}
    # helper functions and folder setup

    # ensure output plots exist
    if (!file.exists("analysis-output/plots")) {
        dir.create("analysis-output/plots", recursive = TRUE)
    }

    # Load helper funcs and dataframes and set directory
    phone_translate <- read.csv("aux-data/phoneme-translate.csv")
    phone_translate$phone_type <- as.factor(phone_translate$phone_type)
    training_lexicon <- read.csv("aux-data/training-lexicon.csv")

    load_eval_files <- function(file_pattern, create_correct_column = TRUE) {
        # find matching files, combine into single df
        setwd("data/evals")
        df_files <- list.files(".", file_pattern)
        df <- dplyr::bind_rows(lapply(df_files, read.csv))
        setwd("../../")

        # Remove unneeded columns and rows
        df <- subset(df, select = -c(timestamp, facilitator, event, item))
        df <- dplyr::filter(df, stimulus != "")

        if (create_correct_column) {
            df$correct <- as.integer(df$stimulus == df$selection)
        }

        # configure data types
        ordered_conditions <- c("Pre-test", "Post-test")
        df <- within(df, {
            pid <- as.factor(pid)
            condition <- factor(
                condition,
                levels = ordered_conditions,
                labels = ordered_conditions
            )
            selection <- as.factor(selection)
            stimulus <- as.factor(stimulus)
        })

        return(df)
    }

    merge_eval_files_with_training <- function(eval_df, train_df) {
        df <- merge(eval_df, train_df, key = "pid", all.x = TRUE)

        df$group <- ifelse(is.na(df$training_word_exposures), "Control", "Experimental")
        df$group <- as.factor(df$group)

        df$training_word_exposures <- replace(
            df$training_word_exposures,
            is.na(df$training_word_exposures),
            0
        )

        # normalize training_word_exposures
        df$training_word_exposures_n <- df$training_word_exposures / max(df$training_word_exposures, na.rm = TRUE)

        return(df)
    }

    bin_lme <- function(formula, data) {
        data <- rlang::enexpr(data)
        model_call <- rlang::expr(lme4::glmer(
            formula = formula,
            data = !!data,
            family = binomial,
            control = lme4::glmerControl(optimizer = "bobyqa")
        ))

        model <- eval(model_call)
        print(summary(model))

        return(model)
    }

    save_plot <- function(plot = NULL, path = NULL, filename = NULL, width = 6, height = 6) {
        if (is.null(plot)) {
            plot <- ggplot2::last_plot()
        }

        if (is.null(path)) {
            path <- "analysis-output/plots"
        }

        if (is.null(filename)) {
            filename <- stringr::str_replace_all(tolower(plot$labels$title), " ", "_")
        }

        filename <- sprintf("%s/%s.png", path, filename)

        ggplot2::ggsave(
            plot = plot,
            file = filename,
            width = width, height = height
        )
    }

    get_logistic_odds_results <- function(model, effect_index = NULL) {
        # https://www.statology.org/how-to-report-logistic-regression-results/

        coeffs <- summary(model)$coefficients

        effect_index <- ifelse(is.null(effect_index), nrow(coeffs))

        coeff <- coeffs[effect_index, 1]
        err <- coeffs[effect_index, 1]

        return(c(
            (exp(coeff)-1)*100,
            exp(coeff + (1.96*err)),
            exp(coeff - (1.96*err))
        ))
    }
```

# TRAINING DATA
```{r load-training-data, echo = FALSE}
    # Load training files from data/training/*.csv

    setwd("data/training")

    training_files <- list.files(".", "*.csv")
    training_data <- data.frame()

    for (idx in seq_along(training_files)) {
        tmp_df <- read.csv(training_files[idx])
        if (nrow(tmp_df) > 0) {
            training_data <- dplyr::bind_rows(training_data, tmp_df)
        }
    }
    setwd("../../")

    # calculate how much time has elapsed between rows
    # from this we can determine training day index
    training_data <- training_data[
        order(training_data$PID, training_data$Timestamp),
    ]

    training_data$datetime <- as.POSIXct(sub("T", " ", training_data$Timestamp))
    # $timedelta will be in seconds
    is_repeated_pid <- training_data$PID == dplyr::lag(training_data$PID)
    training_data$timedelta <- ifelse(
        is_repeated_pid & !is.na(dplyr::lag(training_data$datetime)),
        training_data$datetime - dplyr::lag(training_data$datetime),
        Inf
    )

    # Compute training session idx's
    # we consider a gap of 1 hour or more to count as a new training session
    training_data$training_session_inc <- ifelse(
        training_data$timedelta == Inf,
        0,
        as.integer(training_data$timedelta > 3600)
    )
    training_data$training_session_idx <- cumsum(training_data$training_session_inc)

    tmp_first_day <- data.frame(dplyr::summarise(
        dplyr::group_by(training_data, PID),
        first_day = min(training_session_idx)
    ))

    training_data <- dplyr::left_join(training_data, tmp_first_day, c("PID"))
    training_data$training_session_idx <- training_data$training_session_idx - training_data$first_day

    # Compute level attempt idx's
    is_not_first_row <- is.na(lag(training_data$training_session_idx))
    is_repeated_pid <- training_data$PID != lag(training_data$PID)
    training_data$level_attempt_idx <- ifelse(
        is_not_first_row | is_repeated_pid | is.na(dplyr::lag(training_data$LevelAttemptGuid)),
        1,
        training_data$LevelAttemptGuid != dplyr::lag(training_data$LevelAttemptGuid)
    )
    training_data$level_attempt_idx <- cumsum(training_data$level_attempt_idx)

    # trunc file extension from stimulus column
    training_data$stimulus <- sub("\\..*", "", training_data$Stimulus)

    # parse speaker/phrase from stimulus filename
    stimuli_info <- data.frame(do.call("rbind", strsplit(training_data$stimulus, "-")))
    training_data$speaker <- stimuli_info$X1
    training_data$phrase <- stimuli_info$X2

    # configure data types
    training_data <- within(training_data, {
        pid <- as.factor(PID)
        stimulus <- as.factor(stimulus)
        speaker <- as.factor(speaker)
    })
    training_data <- merge(training_data, training_lexicon, by = "stimulus", all.x = TRUE)
    training_data <- training_data[order(training_data$pid, training_data$Timestamp), ]

    # clear unneeded columns
    training_data <- subset(training_data, select = c(
        Timestamp, datetime, pid, stimulus, Ok, speaker, phrase.y,
        training_session_idx, level_attempt_idx, LevelAttemptGuid
    ))
    training_data <- dplyr::rename(training_data, phrase = phrase.y)

    # Count exposures by VTT file
    exposure_counts_by_stimulus <- data.frame(dplyr::summarise(
        dplyr::group_by(training_data, pid, stimulus, phrase),
        stimulusExposures = sum(Ok)
    ))

    write.csv(exposure_counts_by_stimulus, "analysis-output/exposure_counts_by_stimulus.csv")

    # Count exposures by phrase (each phrase has 4 VTT files)
    exposure_counts_by_phrase <- data.frame(dplyr::summarise(
        dplyr::group_by(training_data, pid, phrase),
        phraseExposures = dplyr::n()
    ))

    write.csv(exposure_counts_by_phrase, "analysis-output/exposure_counts_by_phrase.csv")

    # Count how many total words each participant received
    traing_word_exposures <- data.frame(dplyr::summarise(
        dplyr::group_by(training_data, pid),
        training_word_exposures = sum(Ok)
    ))

    # Given how many of which stimuli each participant was exposed to,
    # calculate how many times each pid was exposed to each phoneme
    exposure_counts_by_phoneme <- merge(exposure_counts_by_stimulus, training_lexicon, by = "stimulus", all.x = TRUE)
    exposure_counts_by_phoneme <- dplyr::rename(exposure_counts_by_phoneme, phrase = phrase.y)

    # validity checking
    missing_pronounciations <- is.na(exposure_counts_by_phoneme$pronounciation)
    words_not_in_lexicon <- exposure_counts_by_phoneme[missing_pronounciations, ]
    if (nrow(words_not_in_lexicon) > 0) {
        print("### ASSERT FAILED: ###")
        print("Words not in the lexicon:")
        print(words_not_in_lexicon$word)
    }
    pronounciation_counts <- data.frame(dplyr::summarise(
        dplyr::group_by(training_lexicon, phrase),
        pronounciations = dplyr::n()
    ))
    pronounciation_counts <- dplyr::filter(pronounciation_counts, pronounciations != 4)
    if (nrow(pronounciation_counts) > 0) {
        print("### ASSERT FAILED: ###")
        print("Words with invalid pronounciation counts")
        print(pronounciation_counts)
    }

    exposure_counts_by_phoneme <- dplyr::mutate(exposure_counts_by_phoneme, across(AA:ZH, ~ .x * stimulusExposures))
    write.csv(exposure_counts_by_phoneme, "analysis-output/exposure_counts_by_phoneme_0.csv")

    p_exposures <- tidyr::gather(exposure_counts_by_phoneme, phoneme, phoneme_exposures, AA:ZH)
    p_exposures$phoneme <- as.factor(p_exposures$phoneme)
    p_exposures <- data.frame(dplyr::summarise(
        dplyr::group_by(p_exposures, pid, phoneme),
        phoneme_exposures = sum(phoneme_exposures)
    ))

    write.csv(p_exposures, "analysis-output/exposure_counts_by_phoneme.csv")

    # Cleanup
    rm(idx)
    rm(tmp_df)
    rm(training_files)
    rm(tmp_first_day)
    rm(stimuli_info)
    rm(exposure_counts_by_stimulus)
    rm(words_not_in_lexicon)
    rm(pronounciation_counts)
    rm(exposure_counts_by_phoneme)
    rm(is_repeated_pid)
    rm(is_not_first_row)
    rm(missing_pronounciations)
```

## Training Reports
```{r create-training-reports, echo = FALSE}
    training_day_summary <- data.frame(dplyr::summarise(
        dplyr::group_by(training_data, pid, training_session_idx),
        startTime = min(datetime),
        stopTime = max(datetime),
        phraseStimCount = sum(Ok),
        durationInM = 60 * as.double(difftime(max(datetime), min(datetime), units = "hours"))
    ))

    stims_per_level <- data.frame(dplyr::summarise(
        dplyr::group_by(training_data, pid, LevelAttemptGuid),
        levelStartTime = min(Timestamp),
        stimCount = sum(Ok)
    ))

    uniq_phrases <- data.frame(dplyr::summarise(
        dplyr::group_by(exposure_counts_by_phrase, pid),
        uniquePhrases = dplyr::n(),
        phrases = paste(phrase, collapse = "|")
    ))

    total_p_exposures_by_pid <- data.frame(dplyr::summarise(
        dplyr::group_by(p_exposures, pid),
        totalPhonemeExposures = sum(phoneme_exposures),
        meanPhonemeExposures = mean(phoneme_exposures),
        stdevPhonemeExposures = sd(phoneme_exposures)
    ))

    untrained_phones <- data.frame(dplyr::summarise(
        dplyr::group_by(dplyr::filter(p_exposures, phoneme_exposures == 0), pid),
        untrainedPhones = paste(phoneme, collapse = "|")
    ))

    training_report <- data.frame(dplyr::summarise(
        dplyr::group_by(training_data, pid),
        first_day = min(datetime),
        lastDay = max(datetime),
        uniqueSessions = max(training_session_idx)+1,
        dateRange = as.integer(max(datetime) - min(datetime)),
        totalPhraseStimExposures = sum(Ok)
    ))

    training_day_summary_by_pid <- data.frame(dplyr::summarise(
        dplyr::group_by(training_day_summary, pid),
        meantrainingSessionDurationM = mean(durationInM)
    ))

    level_attempts_by_pid <- data.frame(dplyr::summarise(
        dplyr::group_by(stims_per_level, pid),
        levelAttempts = dplyr::n()
    ))

    training_report <- merge(training_report, level_attempts_by_pid, by = "pid", keep.x = TRUE)
    training_report <- merge(training_report, training_day_summary_by_pid, by = "pid", keep.x = TRUE)
    training_report$level_attempts_per_session <- training_report$levelAttempts / training_report$uniqueSessions
    training_report <- merge(training_report, total_p_exposures_by_pid, by = "pid", keep.x = TRUE)
    training_report <- merge(training_report, untrained_phones, by = "pid", keep.x = TRUE)
    training_report <- merge(training_report, uniq_phrases, by = "pid", keep.x = TRUE)

    write.csv(training_report, "analysis-output/training_report.csv")

    # Cleanup
    rm(training_day_summary)
    rm(stims_per_level)
    rm(uniq_phrases)
    rm(total_p_exposures_by_pid)
    rm(untrained_phones)
    rm(training_day_summary_by_pid)
    rm(level_attempts_by_pid)
```

# PHONEMES
## Load data
```{r load-phoneme-data, echo = FALSE}
    phone_df <- load_eval_files("_phonemes_")
    phone_df <- merge_eval_files_with_training(phone_df, traing_word_exposures)

    phone_df <- within(phone_df, {
        speaker_gender <- as.factor(toupper(substring(stimfile, 1, 1)))
        stimfile <- as.factor(stimfile)
    })

    # Manually check ratios
    summary(phone_df$correct)
    table(phone_df$pid, phone_df$correct, phone_df$condition)
    table(phone_df$pid, phone_df$correct)
    table(phone_df$condition, phone_df$correct)

    phone_df_with_phone_exposures <- merge(
        phone_df, phone_translate,
        by.x = "stimulus", by.y = "test_word",
        keep.x = TRUE
    )

    phone_df_with_phone_exposures <- dplyr::left_join(
        phone_df_with_phone_exposures,
        p_exposures,
        c("train_phone" = "phoneme", "pid")
    )
    phone_df_with_phone_exposures$train_phone <- as.factor(phone_df_with_phone_exposures$train_phone)

    # Question: Should control group training predictors be converted from NA to 0??
    phone_df_with_phone_exposures$phoneme_exposures <- replace(
        phone_df_with_phone_exposures$phoneme_exposures,
        is.na(phone_df_with_phone_exposures$phoneme_exposures),
        0
    )

    # normalize phoneme exposure counts
    phoneme_exposures <- phone_df_with_phone_exposures$phoneme_exposures
    phone_df_with_phone_exposures$phoneme_exposures_n <- phoneme_exposures / max(phoneme_exposures, na.rm = TRUE)

    ordered_phones <- phone_translate[order(phone_translate$phone_type, phone_translate$test_phone), ]$test_phone
    ordered_phones <- stringi::stri_remove_empty(ordered_phones)
    phone_df_with_phone_exposures <- within(phone_df_with_phone_exposures, {test_phone <- factor(
        test_phone,
        levels = ordered_phones,
        labels = ordered_phones
    )})
```

## Explore and visualize 📈
```{r plot-phoneme-data, echo = FALSE}
#    exposure_counts_by_phone_type <- data.frame(
#        dplyr::summarise(
#            dplyr::group_by(phone_df_with_phone_exposures, pid, condition, test_phone, phone_type),
#            phoneme_exposures = mean(phoneme_exposures),
#        )
#    )
#
#    exposure_counts_by_phone_type <- data.frame(
#        dplyr::summarise(
#            dplyr::group_by(exposure_counts_by_phone_type, pid, phone_type, condition),
#            phoneme_exposures = sum(phoneme_exposures),
#        )
#    )
#
#    test_summary <- data.frame(
#        dplyr::summarise(
#            dplyr::group_by(phone_df_with_phone_exposures, condition, pid, phone_type),
#            correctPortion = 100 * mean(correct),
#            se = 100 * sd(correct) / sqrt(length(correct))
#        )
#    )
#
#    phone_summary_by_type_and_pid <- merge(
#        test_summary,
#        exposure_counts_by_phone_type,
#        by = c("condition", "pid", "phone_type")
#    )
#
#    phone_summary_exp_by_pid <- dplyr::filter(phone_summary_by_type_and_pid, !is.na(phoneme_exposures))
#
#    ggplot2::ggplot(phone_summary_exp_by_pid, ggplot2::aes(
#        x = phoneme_exposures, y = correctPortion,
#        shape = phone_type, group = phone_type, color = phone_type
#    )) +
#        ggplot2::facet_wrap(facets = ggplot2::vars(pid)) +
#        ggplot2::geom_hline(yintercept = 100 / 9, linetype = "dashed", color = "gray") +
#        ggplot2::geom_line() +
#        ggplot2::geom_point(size = 3) +
#        ggplot2::geom_errorbar(
#            ggplot2::aes(ymin = correctPortion - se, ymax = correctPortion + se),
#            width = 500,
#        ) +
#        ggplot2::ylim(0, 100) +
#        ggplot2::labs(
#            colour = "Phoneme Type",
#            shape = "Phoneme Type",
#            x = "Phoneme Exposures",
#            y = "Percentage Correct",
#            title = "Phoneme Recognition (experimental group individuals)"
#        ) +
#        ggplot2::theme_classic() +
#        ggplot2::theme(legend.position = c(0.85, 0.85))
#
#    save_last_plot("phoneme-recognition-exp-group-by-pid.png")
#
#    post_test_summary <- data.frame(
#        dplyr::summarise(
#            dplyr::group_by(phone_df_with_phone_exposures, phone_type, test_phone),
#            correctPortion = 100 * mean(correct),
#            phoneme_exposures = mean(phoneme_exposures),
#            se = 100 * sd(correct) / sqrt(length(correct))
#        )
#    )
#
#    ggplot2::ggplot(post_test_summary, ggplot2::aes(
#        x = phoneme_exposures, y = correctPortion,
#        label = test_phone, color = phone_type
#    )) +
#        ggplot2::geom_hline(yintercept = 100 / 9, linetype = "dashed", color = "gray") +
#    #    ggplot2::geom_line(ggplot2::aes(y = fitLine$fit), color = 'black') +
#    #    ggplot2::geom_ribbon(ggplot2::aes(ymin = fitLine$lwr, ymax = fitLine$upr), alpha = .15, color = 'gray') +
#    #    ggplot2::geom_point(show.legend = FALSE) +
#    #    ggrepel::geom_text_repel(max.overlaps = Inf) +
#        ggplot2::geom_text(size = 3) +
#        #ggplot2::ylim(min(fitLine$lwr), 100) +
#        ggplot2::ylim(0, 100) +
#        ggplot2::labs(
#            colour = "Phoneme Type",
#            x = "Mean Training Exposures",
#            y = "Mean Percentage Correct",
#            title = "Phoneme Recognition (experimental group)"
#        ) +
#        ggplot2::theme_classic() +
#        ggplot2::theme(
#            legend.position = "none",
#            axis.title.x = ggplot2::element_blank(), axis.title.y = ggplot2::element_blank()
#        )
#
#    save_last_plot("phoneme-recognition-by-phone.png", width = 3, height = 3)

    post_test_summary_by_condition <- data.frame(
        dplyr::summarise(
            dplyr::group_by(phone_df_with_phone_exposures, group, condition),
            correctPortion = 100 * mean(correct),
            se = 100 * sd(correct) / sqrt(length(correct))
        )
    )

    dodge <- ggplot2::position_dodge(width = 0.125)

    ggplot2::ggplot(post_test_summary_by_condition, ggplot2::aes(
        x = condition, y = correctPortion,
        group = group, color = group, shape = group
    )) +
        ggplot2::geom_hline(yintercept = 100 / 9, linetype = "dashed", color = "gray") +
        ggplot2::geom_line(position = dodge) +
        ggplot2::geom_point(position = dodge, size = 4) +
        ggplot2::geom_errorbar(
            ggplot2::aes(ymin = correctPortion - se, ymax = correctPortion + se),
            position = dodge,
            width = .125,
            color = "#555555"
        ) +
        ggplot2::ylim(0, 100) +
        ggplot2::labs(
            x = "Test Session",
            y = "Percentage Correct",
            title = "Phoneme Identification Before and After Training Period",
            color = "Group", shape = "Group"
        ) +
        ggplot2::theme_classic() +
        ggplot2::theme(
            legend.position = c(0.85, 0.85),
            legend.background = ggplot2::element_rect(size = 0.5, color = "#888888", fill = "#EEEEEE")
        )

    save_plot()

    phone_exp_post_only <- dplyr::filter(
        phone_df_with_phone_exposures,
        group == "Experimental" & condition == "Post-test"
    )

    post_test_summary_by_pid <- data.frame(
        dplyr::summarise(
            dplyr::group_by(phone_exp_post_only, pid, group, phone_type, test_phone),
            correctPortion = 100 * mean(correct),
            phoneme_exposures = mean(phoneme_exposures),
            se = 100 * sd(correct) / sqrt(length(correct))
        )
    )

    ggplot2::ggplot(post_test_summary_by_pid, ggplot2::aes(
        x = phoneme_exposures, y = correctPortion,
        label = test_phone, color = phone_type
    )) +
        ggplot2::facet_wrap(facets = ggplot2::vars(pid)) +
        ggplot2::geom_hline(yintercept = 100 / 9, linetype = "dashed", color = "gray") +
    #    ggplot2::geom_line(ggplot2::aes(y = fitLine$fit), color = 'black') +
    #    ggplot2::geom_ribbon(ggplot2::aes(ymin = fitLine$lwr, ymax = fitLine$upr), alpha = .15, color = 'gray') +
    #    ggplot2::geom_point(show.legend = FALSE) +
        ggplot2::geom_text(size = 3) +
    #    ggrepel::geom_text_repel(max.overlaps = Inf) +
        #ggplot2::ylim(min(fitLine$lwr), 100) +
        ggplot2::ylim(0, 100) +
        ggplot2::labs(
            color = "Phone type",
            x = "Phoneme Exposures",
            y = "Percentage Correct",
            title = "(Individual's) Effect of Stimulus Exposures on Phoneme Identification"
        ) +
        ggplot2::theme_classic() +
        ggplot2::theme(
            legend.position = c(0.9, 0.9),
            legend.background = ggplot2::element_rect(size = 0.5, color = "#888888", fill = "#EEEEEE")
        )

    save_plot(width = 12)

    post_test_summary_by_phone <- data.frame(
        dplyr::summarise(
            dplyr::group_by(phone_exp_post_only, phone_type, test_phone),
            correctPortion = 100 * mean(correct),
            phoneme_exposures = mean(phoneme_exposures),
            se = 100 * sd(correct) / sqrt(length(correct))
        )
    )

    ggplot2::ggplot(post_test_summary_by_phone, ggplot2::aes(
        x = phoneme_exposures, y = correctPortion,
        label = test_phone, color = phone_type
    )) +
        ggplot2::geom_hline(yintercept = 100 / 9, linetype = "dashed", color = "gray") +
    #    ggplot2::geom_line(ggplot2::aes(y = fitLine$fit), color = 'black') +
    #    ggplot2::geom_ribbon(ggplot2::aes(ymin = fitLine$lwr, ymax = fitLine$upr), alpha = .15, color = 'gray') +
    #    ggplot2::geom_point(show.legend = FALSE) +
        ggplot2::geom_text(size = 3) +
    #    ggrepel::geom_text_repel(max.overlaps = Inf) +
        #ggplot2::ylim(min(fitLine$lwr), 100) +
        ggplot2::ylim(0, 100) +
        ggplot2::labs(
            colour = "Phone Type",
            x = "Phoneme Exposures",
            y = "Percentage Correct",
            title = "Effect of Stimulus Exposures on Phoneme Identification"
        ) +
        ggplot2::theme_classic() +
        ggplot2::theme(
            legend.position = c(0.85, 0.85),
            legend.background = ggplot2::element_rect(size = 0.5, color = "#888888", fill = "#EEEEEE")
        )

    save_plot()
```

```{r plot-phoneme-data2, include = FALSE}
    # extra plots

    # Consonants vs vowels
    post_test_summary_by_type <- data.frame(
        dplyr::summarise(
            dplyr::group_by(phone_df_with_phone_exposures, group, phone_type),
            correctPortion = 100 * mean(correct),
            phoneme_exposures = mean(phoneme_exposures),
            se = 100 * sd(correct) / sqrt(length(correct))
        )
    )

    ggplot2::ggplot(post_test_summary_by_type, ggplot2::aes(
        x = phone_type, y = correctPortion,
        label = phone_type, fill = group
    )) +
        ggplot2::geom_hline(yintercept = 100 / 9, linetype = "dashed", color = "gray") +
        ggplot2::geom_bar(stat = "identity", , position = ggplot2::position_dodge()) +
        ggplot2::ylim(0, 100) +
        ggplot2::labs(
            fill = "Group",
            x = "Phoneme Exposures",
            y = "Percentage Correct",
            title = "Post-test Phoneme Identification"
        ) +
        ggplot2::theme_classic()

    save_plot()

    post_test_summary_by_group <- data.frame(
        dplyr::summarise(
            dplyr::group_by(phone_df_with_phone_exposures, group, phone_type, test_phone),
            correctPortion = 100 * mean(correct),
            phoneme_exposures = mean(phoneme_exposures),
            se = 100 * sd(correct) / sqrt(length(correct))
        )
    )

    ggplot2::ggplot(post_test_summary_by_group, ggplot2::aes(
        x = test_phone, y = correctPortion,
        label = test_phone, fill = group
    )) +
        ggplot2::geom_hline(yintercept = 100 / 9, linetype = "dashed", color = "gray") +
        ggplot2::geom_bar(stat = "identity", , position = ggplot2::position_dodge()) +
        ggplot2::ylim(0, 100) +
        ggplot2::labs(
            fill = "Group",
            x = "Phoneme Exposures",
            y = "Percentage Correct",
            title = "Post-test Phoneme Identification (by phoneme)"
        ) +
        ggplot2::theme_classic()

    save_plot()

```

## Model
```{r model-phoneme-data, echo = FALSE}
    # Question here: should training_word_exposures be NA or 0 for the control group?

    phone_m0 <- bin_lme(
        data = phone_df_with_phone_exposures,
        formula = correct
            ~ training_word_exposures_n * condition
            + (0 + condition | pid)
            + (0 + condition | phone_type / test_phone)
    )

    results_phone_m0 <- get_logistic_odds_results(phone_m0)

    print(sprintf(
        "The odds of correctly specifying a phoneme on the post-test, when trained, increased by %0.f%% (95%% CI [%0.2f, %0.2f]).",
        results_phone_m0[1], results_phone_m0[2], results_phone_m0[3]
    ))

    # @TODO: Question - do the lines above need to be de-transformed? training_word_exposures_n is min-max normalized

    exp_post_only <- dplyr::filter(phone_df_with_phone_exposures, group == "Experimental", condition == "Post-test")
    phone_m1 <- bin_lme(
        data = exp_post_only,
        formula = correct
            ~ phoneme_exposures_n
            + (1 | pid)
            + (1 | phone_type / test_phone)
    )

    results_phone_m1 <- get_logistic_odds_results(phone_m1)

    print(sprintf(
        "The odds of correctly specifying a phoneme on the post-test, when trained, increased by %0.f%% (95%% CI [%0.2f, %0.2f]).",
        results_phone_m1[1], results_phone_m1[2], results_phone_m1[3]
    ))

```

# PROSODY
## Load Data
```{r load-prosody-data, echo = FALSE}
    prosody_df <- load_eval_files("_prosody_")
    prosody_df <- merge_eval_files_with_training(prosody_df, traing_word_exposures)

    prosody_df <- tidyr::separate(
        data = prosody_df, col = stimfile,
        into = "sentence_id",
        sep = "_",
        extra = "drop",
        remove = FALSE
    )
    type_starts_with_f <- substring(prosody_df$stimfile, 1, 1) == "f"
    prosody_df$prosody_type <- as.factor(ifelse(type_starts_with_f, "Focus", "Phrase"))
    prosody_df$stimfile <- as.factor(prosody_df$stimfile)

    #prosody_df <- data.frame(dplyr::summarise(
    #    dplyr::group_by(prosody_df, pid, condition, sentence_id, prosody_type),
    #    training_word_exposures = mean(training_word_exposures),
    #    portionCorrect = mean(correct)
    #))

    focus_df <- dplyr::filter(prosody_df, prosody_df$prosody_type == "Focus")
    focus_df$sentence_id <- as.factor(focus_df$sentence_id)

    phrase_df <- dplyr::filter(prosody_df, prosody_df$prosody_type == "Phrase")
    phrase_df$sentence_id <- as.factor(phrase_df$sentence_id)

    # cleanup
    rm(type_starts_with_f)
```

## Plot Focus Discrimination
```{r plot-focus-data, echo = FALSE}

    focus_test_session_comparison_by_group <- dplyr::summarise(
        dplyr::group_by(focus_df, group, condition),
        correctPortion = 100 * mean(correct),
        se = 100 * sd(correct) / sqrt(length(correct))
    )

    dodge <- ggplot2::position_dodge(width = 0.125)

    ggplot2::ggplot(focus_test_session_comparison_by_group, ggplot2::aes(
        x = condition, y = correctPortion,
        group = group, color = group, shape = group
    )) +
        ggplot2::geom_hline(yintercept = 50, linetype = "dashed", color = "gray") +
        ggplot2::geom_line(position = dodge) +
        ggplot2::geom_point(position = dodge, size = 4) +
        ggplot2::geom_errorbar(
            ggplot2::aes(ymin = correctPortion - se, ymax = correctPortion + se),
            position = dodge,
            width = .125,
            color = "#555555"
        ) +
        ggplot2::ylim(0, 100) +
        ggplot2::labs(
            x = "Test Session",
            y = "Percentage Correct",
            title = "Focus Discrimination Before and After Training",
            color = "Group", shape = "Group"
        ) +
        ggplot2::theme_classic() +
        ggplot2::theme(
            legend.position = c(0.85, 0.85),
            legend.background = ggplot2::element_rect(size = 0.5, color = "#888888", fill = "#EEEEEE")
        )

    save_plot()

    focus_post_experimental_only <- dplyr::filter(focus_df, group == "Experimental", condition == "Post-test")

    focus_post_experimental_only_summary <- dplyr::summarise(
        dplyr::group_by(focus_post_experimental_only, pid, training_word_exposures),
        correctPortion = 100 * mean(correct),
        se = 100 * sd(correct) / sqrt(length(correct))
    )

    ggplot2::ggplot(focus_post_experimental_only_summary, ggplot2::aes(
        x = training_word_exposures, y = correctPortion
    )) +
        ggplot2::geom_hline(yintercept = 50, linetype = "dashed", color = "gray") +
        ggplot2::geom_point(position = dodge, size = 4) +
        ggplot2::geom_errorbar(
            ggplot2::aes(ymin = correctPortion - se, ymax = correctPortion + se),
            position = dodge,
            width = .125,
            color = "#555555"
        ) +
        ggplot2::ylim(0, 100) +
        ggplot2::xlim(0, NA) +
        ggplot2::labs(
            x = "Training Word Exposures",
            y = "Percentage Correct",
            title = "Word Exposure Effect on Focus Discrimination"
        ) +
        ggplot2::theme_classic()

    save_plot()
```

## Focus - Model & Test
```{r model-focus-data, echo = FALSE}
    focus_model <- function(formula) bin_lme(formula = formula, data = focus_df)

    focus_m0 <- bin_lme(
        data = focus_df,
        formula = correct
            ~ training_word_exposures_n * condition
            + (condition | pid)
            + (1 | sentence_id / stimulus)
    )

    results_focus_m0 <- get_logistic_odds_results(focus_m0)
    print(sprintf(
        "The odds of correctly identifying the emphasized word after training, increased by %0.f%% (95%% CI [%0.2f, %0.2f]).",
        results_focus_m0[1], results_focus_m0[2], results_focus_m0[3]
    ))

```

## Plot Phrase Discrimination
```{r plot-phrase-data, echo = FALSE}

    phrase_test_session_by_group <- dplyr::summarise(
        dplyr::group_by(phrase_df, group, condition),
        correctPortion = 100 * mean(correct),
        se = 100 * sd(correct) / sqrt(length(correct))
    )

    dodge <- ggplot2::position_dodge(width = 0.125)

    ggplot2::ggplot(phrase_test_session_by_group, ggplot2::aes(
        x = condition, y = correctPortion,
        group = group, color = group, shape = group
    )) +
        ggplot2::geom_hline(yintercept = 50, linetype = "dashed", color = "gray") +
        ggplot2::geom_line(position = dodge) +
        ggplot2::geom_point(position = dodge, size = 4) +
        ggplot2::geom_errorbar(
            ggplot2::aes(ymin = correctPortion - se, ymax = correctPortion + se),
            position = dodge,
            width = .125,
            color = "#555555"
        ) +
        ggplot2::ylim(0, 100) +
        ggplot2::labs(
            x = "Test Session",
            y = "Percentage Correct",
            title = "Phrase Discrimination Before and After Training",
            color = "Group", shape = "Group"
        ) +
        ggplot2::theme_classic() +
        ggplot2::theme(
            legend.position = c(0.85, 0.85),
            legend.background = ggplot2::element_rect(size = 0.5, color = "#888888", fill = "#EEEEEE")
        )

    save_plot()

    phrase_post_exp_only <- dplyr::filter(phrase_df, group == "Experimental", condition == "Post-test")

    phrase_post_exp_only_summary <- dplyr::summarise(
        dplyr::group_by(phrase_post_exp_only, pid, training_word_exposures),
        correctPortion = 100 * mean(correct),
        se = 100 * sd(correct) / sqrt(length(correct))
    )

    ggplot2::ggplot(phrase_post_exp_only_summary, ggplot2::aes(
        x = training_word_exposures, y = correctPortion
    )) +
        ggplot2::geom_hline(yintercept = 50, linetype = "dashed", color = "gray") +
        ggplot2::geom_point(position = dodge, size = 4) +
        ggplot2::geom_errorbar(
            ggplot2::aes(ymin = correctPortion - se, ymax = correctPortion + se),
            position = dodge,
            width = .125,
            color = "#555555"
        ) +
        ggplot2::ylim(0, 100) +
        ggplot2::xlim(0, NA) +
        ggplot2::labs(
            x = "Training Word Exposures",
            y = "Percentage Correct",
            title = "Word Exposure Effect on Phrase Boundary Discrimination"
        ) +
        ggplot2::theme_classic()

    save_plot()
```

## Phrase Boundary - Model & Test
```{r model-phrase-data, echo = FALSE}
    phrase_m0 <- bin_lme(
        data = phrase_df,
        formula = correct
            ~ training_word_exposures_n * condition
            + (training_word_exposures_n | pid)
            + (condition | pid)
            + (1 | sentence_id / stimulus)
    )

    results_phrase_m0 <- get_logistic_odds_results(phrase_m0)
    print(sprintf(
        "The odds of correctly identifying the phrase boundary word after training, increased by %0.f%% (95%% CI [%0.2f, %0.2f]).",
        results_phrase_m0[1], results_phrase_m0[2], results_phrase_m0[3]
    ))
```

# INTEGRATION
## Load Data
```{r load-integration-data, echo = FALSE}
    integration_df <- load_eval_files("_integration_", create_correct_column = FALSE)
    integration_df <- merge_eval_files_with_training(integration_df, traing_word_exposures)

    integration_df <- within(integration_df, {
        integrated <- 1 - as.integer(mapply(grepl, pattern = selection, x = stimulus))
        auditory_stim <- as.factor(substring(stimulus, 1, 2))
        tactile_stim <- as.factor(substring(stimulus, 4, 5))
        speaker <- as.integer(substring(audibleFile, 8, 9))
        speaker_gender <- as.factor(substring(stimfile, 1, 1))
    })
```

## Explore & Visualize 📈
```{r plot-integration-data, echo = FALSE}
    integration_summary <- dplyr::summarise(
        dplyr::group_by(integration_df, group, condition),
        correctPortion = 100 * mean(integrated),
        se = 100 * sd(integrated) / sqrt(length(integrated)),
        training_word_exposures = mean(training_word_exposures),
    )

    ggplot2::ggplot(integration_summary, ggplot2::aes(
        x = condition, y = correctPortion,
        group = group, color = group, shape = group
    )) +
        ggplot2::geom_hline(yintercept = 0, linetype = "dashed", color = "gray") +
        ggplot2::geom_line(position = dodge) +
        ggplot2::geom_point(position = dodge, size = 4) +
        ggplot2::geom_errorbar(
            ggplot2::aes(ymin = correctPortion - se, ymax = correctPortion + se),
            position = dodge,
            width = .125,
            color = "#555555"
        ) +
        ggplot2::ylim(0, 100) +
        ggplot2::labs(
            x = "Test Session",
            y = "Percentage Integrated",
            title = "Perceptual Integration Before and After Training",
            color = "Group", shape = "Group"
        ) +
        ggplot2::theme_classic() +
        ggplot2::theme(
            legend.position = c(0.85, 0.85),
            legend.background = ggplot2::element_rect(size = 0.5, color = "#888888", fill = "#EEEEEE")
        )

    save_plot()

    integration_post_exp_only <- dplyr::filter(integration_df, group == "Experimental", condition == "Post-test")

    integration_post_exp_only_summary <- dplyr::summarise(
        dplyr::group_by(integration_post_exp_only, pid, training_word_exposures),
        integratedPortion = 100 * mean(integrated),
        se = 100 * sd(integrated) / sqrt(length(integrated))
    )

    ggplot2::ggplot(integration_post_exp_only_summary, ggplot2::aes(
        x = training_word_exposures, y = integratedPortion
    )) +
        ggplot2::geom_hline(yintercept = 0, linetype = "dashed", color = "gray") +
        ggplot2::geom_point(position = dodge, size = 4) +
        ggplot2::geom_errorbar(
            ggplot2::aes(ymin = integratedPortion - se, ymax = integratedPortion + se),
            position = dodge,
            width = .125,
            color = "#555555"
        ) +
        ggplot2::ylim(0, 100) +
        ggplot2::xlim(0, NA) +
        ggplot2::labs(
            x = "Training Word Exposures",
            y = "Percentage Integrated",
            title = "Word Exposure Effect on Perceptual Integration"
        ) +
        ggplot2::theme_classic()

    save_plot()

```

## Model & Test
```{r model-integration-data, echo = FALSE}
    integration_m0 <- bin_lme(
        data = integration_df,
        formula = integrated
            ~ training_word_exposures_n * condition
            + (condition | pid)
            + (1 | tactile_stim)
            + (1 | auditory_stim)
            + (1 | speaker_gender / speaker)
    )

    results_integration_m0 <- get_logistic_odds_results(integration_m0)
    print(sprintf(
        "The odds of integrating percepts after training, increased by %0.f%% (95%% CI [%0.2f, %0.2f]).",
        results_integration_m0[1], results_integration_m0[2], results_integration_m0[3]
    ))

```
